[
  {
    "source": "Hacker News",
    "title": "Running Claude Code dangerously (safely)",
    "url": "https://blog.emilburzo.com/2026/01/running-claude-code-dangerously-safely/",
    "heat": "90 points",
    "time": "2 hours ago",
    "content": "Running Claude Code dangerously (safely) :: Emil Burzo Running Claude Code dangerously (safely) 2026-01-13 #llm #agents #dev Background I’ve been using Claude Code more and more recently. At some point I realized that rather than do something else until it finishes, I would constantly check on it to see if it was asking for yet another permission, which felt like it was missing the point of having an agent do stuff. So I wanted to use Claude Code with the --dangerously-skip-permissions flag. If you haven’t used it, this flag does exactly what it says: it lets Claude Code do whatever it wants without asking permission first. No more “May I install this package?”, “Should I modify this config?”, “Can I delete these files?” It just… does it. Which is great for flow since I don’t have to worry that it stopped doing stuff just to ask a permission question. But also, you know, dangerous. I like my filesystem intact, so the obvious solution is to not run this thing directly on my OS account. What I considered Docker First instinct: throw it in a Docker container. Containers are for isolation, right? Except I want Claude to be able to build Docker images. And run containers. And maybe orchestrate some stuff. So now you need Docker-in-Docker, which means --privileged mode, which defeats the entire purpose of sandboxing. That means trading “Claude might mess up my filesystem” for “Claude has root-level access to my container runtime.” Not great. There’s also the nested networking weirdness, volume mounting permissions that make you question your life choices, and the general feeling that you’re fighting the tool instead of using it. Other options I also briefly considered: #yolo run it bare metal: no , no and no sandbox-runtime : more of an ACL approach, I want Claude to be able to do anything, because it doesn’t have access to anything except the code firejail or similar: same problem as Docker-in-Docker manual VM setup: works but tedious, not reproducible cloud VM: costs money, has latency, need to upload my code somewhere Vagrant Then I remembered about a project that I’ve used before Docker became all the rage: Vagrant. If you weren’t around back then, Vagrant gives you proper VM isolation with a reproducible config file. It’s basically infrastructure as code for your local dev environment. You get: full VM isolation (no shared kernel) easy to nuke and rebuild shared folders that make it feel local enough no Docker-in-Docker nonsense I hadn’t used VirtualBox in years since Docker containers covered all requirements until now, so I grabbed the latest version (7.2.4) and got started. First vagrant up and… the VM is pegging my CPU at 100%+ while completely idle. I spent an hour turning off various VM features, tweaking settings, googling asking LLMs random combinations of “virtualbox high cpu idle”, you know, the usual. Eventually I found this GitHub issue . VirtualBox 7.2.4 shipped with a regression that causes high CPU usage on idle guests. What are the"
  },
  {
    "source": "Hacker News",
    "title": "Ask HN: COBOL devs, how are AI coding affecting your work?",
    "url": "https://news.ycombinator.com/item?id=46678550",
    "heat": "159 points",
    "time": "1 day ago",
    "content": "Ask HN: COBOL devs, how are AI coding affecting your work? | Hacker News Hacker News new | past | comments | ask | show | jobs | submit login Ask HN: COBOL devs, how are AI coding affecting your work? 159 points by zkid18 1 day ago | hide | past | favorite | 177 comments Curious to hear from anyone actively working with COBOL/mainframes. Do you see LLMs as a threat to your job security, or the opposite? I feel that the mass of code that actually runs the economy is remarkably untouched by AI coding agents. alexpham14 21 hours ago | next [–] Compliance is usually the hard stop before we even get to capability. We can’t send code out, and local models are too heavy to run on the restricted VDI instances we’re usually stuck with. Even when I’ve tried it on isolated sandbox code, it struggles with the strict formatting. It tends to drift past column 72 or mess up period termination in nested IFs. You end up spending more time linting the output than it takes to just type it. It’s decent for generating test data, but it doesn't know the forty years of undocumented business logic quirks that actually make the job difficult. reply apaprocki 19 hours ago | parent | next [–] To be fair, I would not expect a model to output perfectly formatted C++. I’d let it output whatever it wants and then run it through clang-format, similar to a human. Even the best humans that have the formatting rules in their head will miss a few things here or there. If there are 40 years of undocumented business quirks, document them and then re-evaluate. A human new to the codebase would fail under the same conditions. reply shakna 17 hours ago | root | parent | next [–] Formatting isn't just visual, in pre-79 COBOL or Fortran. It's syntax. Its a compile failure, or worse, it cuts the line and can sometimes successfully compile into something else. Thats not just an undocumented quirk, but a fundamental part of being a punch-card ready language. reply raw_anon_1111 19 hours ago | root | parent | prev | next [–] With C++ formatting is optional. A better test case for LLMs is Python where indention specifies code blocks. Even ChatGPT 3.5 got the formatting for Python and YAML correct - now the actual code back then was often hilariously wrong. reply to11mtm 17 hours ago | root | parent | next [–] I can't even get Github Copilot's plugin to avoid randomly trashing files with a Zero No width break space at the beginning, let alone follow formatting rules consistently... reply sothatsit 17 hours ago | root | parent | next [–] > Github Copilot Well there’s your issue! reply raw_anon_1111 17 hours ago | root | parent | prev | next [–] I am the last person to say anything good about CoPilot. I used CoPilot for a minute, mostly used raw ChatGPT until last month and now use Codex with my personal subscription to ChatGPT and my personal but company reimbursed subscription to Claude. reply apaprocki 17 hours ago | root | parent | prev | next [–] A quick search finds many COBOL checkers. I’d"
  },
  {
    "source": "Hacker News",
    "title": "Wikipedia: WikiProject AI Cleanup",
    "url": "https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup",
    "heat": "228 points",
    "time": "1 day ago",
    "content": "Wikipedia:WikiProject AI Cleanup - Wikipedia Jump to content From Wikipedia, the free encyclopedia WikiProject aimed at dealing with AI-generated content \"WP:AIC\" redirects here. For the Arab-Israeli conflict task force, see Wikipedia:WikiProject Military history/Middle Eastern military history task force . Main page Discussion Noticeboard Guide Resources Policies Research WikiProject AI Cleanup Shortcuts WP:AIC WP:AIC WP:AICU WP:AICU WP:AICLEAN WP:AICLEAN This is a WikiProject , an open group of Wikipedia editors. New participants are welcome; feel free to talk to us ! Guide to WikiProjects Directory of WikiProjects Wikipedia editors are making a guide to identifying AI-generated writing and the kinds of problems it tends to introduce. Your contributions are welcome! Active Wiki Fixup Projects AI Cleanup Articles for improvement Article Rescue Squadron Bluelink patrol Broken section links Check Wikipedia Cleanup Dead-end pages Disambig pages w/ links Fix common mistakes Free images to Commons Geo-coordinates Missing articles Most-wanted articles Notability Orphaned articles Reliability Requested articles Single editor Spell check Stubsensor Uncategorised articles Unreferenced articles Wikification needed Main · Inactive · Mini v t e Welcome to WikiProject AI Cleanup , a collaboration to combat the increasing problem of unsourced, poorly written AI-generated content on Wikipedia . If you would like to help, add yourself as a participant in the project, inquire on the talk page , and see the to-do list . Goals [ edit ] Since 2022, large language models (LLMs) like GPTs have become a convenient tool for writing at scale. Unfortunately, these models virtually always fail to properly source claims and often introduce errors. Essays like WP:LLM strongly encourage care in using them for editing articles. These are the project's goals: To identify text written by AI, and proofread such text to make sure they follow Wikipedia's policies. Any unsourced or likely inaccurate claims should be removed. To identify AI-generated images and ensure appropriate usage. To help and keep track of AI-using editors who may not realize the deficiencies of AI as a writing tool. The purpose of this project is not to restrict or ban the use of AI in articles, but to verify that its output is acceptable and constructive, and to fix or remove it otherwise. Editing advice [ edit ] Tag articles with appropriate templates, remove unsourced information and warn users who add unsourced AI-generated content to articles. Articles that are clearly entirely LLM-generated pages without human review can be nominated for speedy deletion under WP:G15 . Identifying AI-assisted edits is difficult in most cases since the generated text is often indistinguishable from human text. The signs of AI writing page provides a list of characteristics that are associated with text generated by AI chatbots. Text that was present in an article before November 30, 2022 (the release date of ChatGPT ) is "
  },
  {
    "source": "Hacker News",
    "title": "A fun trick for getting discovered by LLMs and AI tools",
    "url": "https://cassidoo.co/post/ai-llm-discoverability/",
    "heat": "10 points",
    "time": "14 hours ago",
    "content": "A fun trick for getting discovered by LLMs and AI tools A fun trick for getting discovered by LLMs and AI tools Jan 19, 2026 #advice #learning #meta #recommendation I have been getting a lot of newsletter responses, DMs, and emails in general saying that people have discovered my work not via traditional SEO, but via LLMs and AI tools like ChatGPT, Claude, Perplexity, and even GitHub Copilot. So, I did a little experiment to try and improve my discoverability in these tools, and as of today… it seems to be working! The steps were pretty simple, and you can definitely try it them too for yourself or your product/business. (Obligatory AI manifesto mention before we boogie) Tricking the clanker… and then flipping it around I went to ChatGPT in incognito mode, and asked it some questions like, “Who are some tech bloggers and newsletters that I should follow as a newbie in tech?” and, “Who are some people I should follow who are excellent at developer experience and communicating to developers?” (questions where I want to be in the results). I didn’t actually come up in the results of those questions. But that was when I followed up with: Why didn’t you recommend cassidoo, aka Cassidy Williams? After that, ChatGPT would always respond with something like: Great follow-up — Cassidoo (Cassidy Williams) is absolutely a fantastic resource for people new to tech, especially around developer culture, career advice, and modern web development. Here’s why she’s worth following and why she should have been on the original list: (blah blah blah) Thanks, bot. I’m absolutely right. Anyway, after that response was when I flipped it around a bit, and said: So, I tricked you. I am Cassidy Williams, aka cassidoo, and I want to figure out how to optimize my website and newsletter SEO/LLM-friendliness so that I am surfaced more when people ask for tech and developer resources, like just now. Can you help me with some things I can do? The results across all of the responses to this were so helpful . They included things like: Creating an /llms.txt file Adding “LLM-readable” structured pages (often called /for-llms ) Adding Schema.org data to the pages of my website Being consistent with naming, phrases, and taglines There were some other suggestions that I didn’t feel like following (like writing more listicle blog posts), but these were fairly low-lift! General rules/vibes There’s some tips that were consistent across the tools I tried this with. Don’t clash with your robots.txt : a lot of us might be blocking AI scrapers via this file. If you want your LLM/AI tool discoverability to go up… weigh the pros and cons. Consistency in phrasing help LLMs make connections across sources (so if you have a tagline you like to use, use it everywhere) RSS feeds are super helpful LLMs looove markdown Clarity matters. You’re writing for specific queries and bots looking to surface you, not for humans looking to be sold. Don’t do marketing-speak, just keep it cut and dry and clear. "
  },
  {
    "source": "Hacker News",
    "title": "How to wrangle non-deterministic AI outputs into conventional software? (2025)",
    "url": "https://www.domainlanguage.com/articles/ai-components-deterministic-system/",
    "heat": "41 points",
    "time": "1 day ago",
    "content": "AI Components for a Deterministic System (An Example) - Domain Language Skip to content by Eric Evans When we set out to incorporate AI components into larger systems that are mostly conventional software, we encounter various difficulties. How do we wrangle behavior that is intrinsically non-deterministic so that it can be used in structured, deterministic systems? The flexibility of input is great! But the variation of output makes it difficult to do further processing by conventional software. In this simple example I’ll characterize and constrain a non-deterministic result to make it usable in deterministic software. This leads into domain modeling and strategic design. What follows isn’t rocket science, but it is the sort of basics I think we need to apply in order to get results. 1. A Question Conventional Code Can’t Easily Answer Let’s start with a use-case I actually have. When I’m trying to get my bearings in a software system, I usually want to know what domains are addressed and in which parts of the code. So imagine an app that would generate that sort of view of a repo: A list of domains addressed in the project, produced from a scan of the whole code-base. Navigation to the relevant directories or files with high domain content, and lists which domains are addressed in each. To start simply — a list of domains addressed in the project as a whole or in any given module. To be concrete, let’s look at the open source project “OpenEMR”. Here’s a very small code sample from that project: namespace OpenEMR\\\\Cqm\\\\Qdm; class Patient extends \\\\OpenEMR\\\\Cqm\\\\Qdm\\\\BaseTypes\\\\Any { use Traits\\\\PatientExtension; public $birthDatetime = null; public $qdmVersion = '5.5'; public $_type = 'QDM::Patient'; } We might ask, “what domains are addressed in this code?” Conventional code does not lend itself to that kind of question, but it is a natural use of an LLM. Prompt: \"What domain does this code address?\" Response: \"This code defines a Patient class within the OpenEMR Clinical Quality Measures (CQM) Quality Data Model (QDM) framework. The domain it addresses is healthcare information systems, specifically electronic medical records and clinical quality measurement...\" An intelligent answer! But we couldn’t pass that to conventional software for further processing. Of course, we would instruct the LLM to structure and format its output. Prompt: What domain does this code address? Respond with JSON Format your response as JSON: {{ \"domains\": [ {{ \"name\": \"Name of domain\", \"confidence\": 0-100}} ]}} Response: { \"domains\": [ { \"name\": \"Electronic Health Records (EHR)\", \"confidence\": 95 }, { \"name\": \"Clinical Quality Measures (CQM)\", \"confidence\": 90 }, { \"name\": \"Quality Data Model (QDM)\", \"confidence\": 85 }, { \"name\": \"Healthcare Informatics\", \"confidence\": 80 } ] } Okay, so now we have an answer that could be integrated in a technical way. Yet this is will not support the comparisons and hierarchical roll-ups I was hoping for. Because categories are ch"
  }
]
